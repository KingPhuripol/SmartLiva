# ‚ö° Deploy SmartLiva ‡∏ö‡∏ô Vercel (‡πÄ‡∏£‡πá‡∏ß‡∏™‡∏∏‡∏î!)

## üéØ Strategy: Frontend (Vercel) + Backend (Render)

- **Frontend**: Next.js ‡∏ö‡∏ô Vercel ‚Üí ‚ö° ‡πÄ‡∏£‡πá‡∏ß‡∏°‡∏≤‡∏Å
- **Backend**: FastAPI ‡∏ö‡∏ô Render ‚Üí üÜì Free tier ‡∏î‡∏µ
- **Total Cost**: $0/month (Free tier ‡∏ó‡∏±‡πâ‡∏á‡∏Ñ‡∏π‡πà)

---

## üì¶ Part 1: Deploy Backend ‡∏ö‡∏ô Render

### 1Ô∏è‚É£ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Backend

```bash
cd /Users/king_phuripol/Work/SmartLab/SmartLiva/app/backend
```

### 2Ô∏è‚É£ ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Render

1. ‡πÄ‡∏õ‡∏¥‡∏î: https://render.com
2. **Sign in with GitHub**
3. **New +** ‚Üí **Web Service**
4. ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å repository: `KingPhuripol/SmartLiva`
5. **Root Directory**: `app/backend`

### 3Ô∏è‚É£ Configure

**Settings:**
```yaml
Name: smartliva-backend
Region: Singapore (‡πÉ‡∏Å‡∏•‡πâ‡∏ó‡∏µ‡πà‡∏™‡∏∏‡∏î)
Branch: main
Root Directory: app/backend
Runtime: Python 3
Build Command: pip install -r requirements.txt
Start Command: uvicorn app.main:app --host 0.0.0.0 --port $PORT
```

**Environment Variables:**
```bash
OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-5-mini-2025-08-07
MAX_TOKENS=2000
TEMPERATURE=0.7
ENVIRONMENT=production
PORT=10000
```

### 4Ô∏è‚É£ Deploy

- ‡∏Ñ‡∏•‡∏¥‡∏Å **Create Web Service**
- ‡∏£‡∏≠ 3-5 ‡∏ô‡∏≤‡∏ó‡∏µ
- ‡πÑ‡∏î‡πâ URL: `https://smartliva-backend.onrender.com`

### 5Ô∏è‚É£ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Backend

```bash
curl https://smartliva-backend.onrender.com/health
```

---

## üé® Part 2: Deploy Frontend ‡∏ö‡∏ô Vercel

### 1Ô∏è‚É£ ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Frontend

```bash
cd /Users/king_phuripol/Work/SmartLab/SmartLiva/app/frontend
```

### 2Ô∏è‚É£ Update API URL

‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ü‡∏•‡πå `.env.production`:

```bash
NEXT_PUBLIC_API_URL=https://smartliva-backend.onrender.com
```

### 3Ô∏è‚É£ ‡πÑ‡∏õ‡∏ó‡∏µ‡πà Vercel

1. ‡πÄ‡∏õ‡∏¥‡∏î: https://vercel.com
2. **Sign in with GitHub**
3. **Add New** ‚Üí **Project**
4. **Import** repository: `KingPhuripol/SmartLiva`

### 4Ô∏è‚É£ Configure

**Project Settings:**
```yaml
Framework Preset: Next.js
Root Directory: app/frontend
Build Command: npm run build
Output Directory: .next
Install Command: npm install
```

**Environment Variables:**
```bash
NEXT_PUBLIC_API_URL=https://smartliva-backend.onrender.com
```

### 5Ô∏è‚É£ Deploy

- ‡∏Ñ‡∏•‡∏¥‡∏Å **Deploy**
- ‡∏£‡∏≠ 1-2 ‡∏ô‡∏≤‡∏ó‡∏µ
- ‡πÑ‡∏î‡πâ URL: `https://smartliva.vercel.app`

### 6Ô∏è‚É£ ‡∏ó‡∏î‡∏™‡∏≠‡∏ö Frontend

‡πÄ‡∏õ‡∏¥‡∏î‡πÄ‡∏ö‡∏£‡∏≤‡∏ß‡πå‡πÄ‡∏ã‡∏≠‡∏£‡πå:
```
https://smartliva.vercel.app
```

---

## üîß Update Frontend Code

‡πÉ‡∏´‡πâ‡πÅ‡∏ô‡πà‡πÉ‡∏à‡∏ß‡πà‡∏≤ frontend ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å API ‡∏ú‡πà‡∏≤‡∏ô `NEXT_PUBLIC_API_URL`:

### ‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÉ‡∏ô `src/lib/api.ts`:

```typescript
const API_URL = process.env.NEXT_PUBLIC_API_URL || 'http://localhost:8000';

export const api = {
  predict: async (imageData: string) => {
    const response = await fetch(`${API_URL}/predict`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ image: imageData })
    });
    return response.json();
  },
  
  chat: async (message: string) => {
    const response = await fetch(`${API_URL}/chat`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({ message })
    });
    return response.json();
  }
};
```

---

## üìä ‡πÄ‡∏õ‡∏£‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏£‡πá‡∏ß

| Platform           | Cold Start | Response Time | Uptime      |
| ------------------ | ---------- | ------------- | ----------- |
| **Vercel**         | ~100ms     | ‚ö° 50-100ms   | 99.99%      |
| **Render (Free)**  | ~30s       | 200-500ms     | 99.9%       |
| **Railway (Free)** | ~45s       | 300-700ms     | 99.5%       |

**Note:** Render free tier ‡∏°‡∏µ cold start ~30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô 15 ‡∏ô‡∏≤‡∏ó‡∏µ

---

## üöÄ Optimizations

### 1. Enable Render Auto-Deploy

Render ‚Üí Settings ‚Üí Auto-Deploy: **Yes**
- Auto-deploy ‡πÄ‡∏°‡∏∑‡πà‡∏≠ push to `main`

### 2. Keep Backend Warm (Optional)

‡πÉ‡∏ä‡πâ Cron job ping backend ‡∏ó‡∏∏‡∏Å 10 ‡∏ô‡∏≤‡∏ó‡∏µ:

**Vercel Cron** (`vercel.json`):
```json
{
  "crons": [
    {
      "path": "/api/ping-backend",
      "schedule": "*/10 * * * *"
    }
  ]
}
```

**API Route** (`pages/api/ping-backend.ts`):
```typescript
export default async function handler(req, res) {
  try {
    await fetch('https://smartliva-backend.onrender.com/health');
    res.status(200).json({ status: 'pinged' });
  } catch (error) {
    res.status(500).json({ error: 'Failed to ping' });
  }
}
```

---

## üí∞ ‡∏Ñ‡πà‡∏≤‡πÉ‡∏ä‡πâ‡∏à‡πà‡∏≤‡∏¢

### Free Tier:

**Vercel:**
- ‚úÖ Bandwidth: 100 GB/month
- ‚úÖ Builds: 6,000 minutes/month
- ‚úÖ Serverless Functions: 100 GB-hours
- ‚úÖ Custom Domains: Unlimited

**Render:**
- ‚úÖ 750 hours/month (‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö 1 service)
- ‚úÖ 512 MB RAM
- ‚úÖ Cold start ‡∏´‡∏•‡∏±‡∏á 15 ‡∏ô‡∏≤‡∏ó‡∏µ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ

**Total: $0/month** üéâ

---

## ‚ö†Ô∏è Limitations

### Render Free Tier:

- ‚ùå Cold start ~30 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ (‡πÅ‡∏Å‡πâ‡πÑ‡∏î‡πâ‡∏î‡πâ‡∏ß‡∏¢ ping)
- ‚ùå Sleep ‡∏´‡∏•‡∏±‡∏á 15 ‡∏ô‡∏≤‡∏ó‡∏µ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡πÉ‡∏ä‡πâ
- ‚ùå RAM 512 MB (‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö FastAPI + OpenAI API)

### Solutions:

1. **Upgrade Render**: $7/month ‚Üí ‡πÑ‡∏°‡πà‡∏°‡∏µ cold start
2. **‡πÉ‡∏ä‡πâ UptimeRobot**: Ping backend ‡∏ó‡∏∏‡∏Å 5 ‡∏ô‡∏≤‡∏ó‡∏µ (Free)
3. **‡πÉ‡∏ä‡πâ Vercel Cron**: Ping ‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥

---

## üîÑ Auto-Deploy Workflow

1. **Push code** ‡πÑ‡∏õ GitHub:
   ```bash
   git add .
   git commit -m "Update feature"
   git push origin main
   ```

2. **Auto-Deploy:**
   - ‚úÖ Vercel deploy frontend ‡πÉ‡∏ô ~1 ‡∏ô‡∏≤‡∏ó‡∏µ
   - ‚úÖ Render deploy backend ‡πÉ‡∏ô ~3 ‡∏ô‡∏≤‡∏ó‡∏µ

3. **Done!** üéâ

---

## üìù Custom Domains (Optional)

### Vercel:
1. Settings ‚Üí Domains
2. ‡πÄ‡∏û‡∏¥‡πà‡∏°: `smartliva.com`
3. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ DNS ‡∏ï‡∏≤‡∏°‡∏ó‡∏µ‡πà Vercel ‡πÅ‡∏ô‡∏∞‡∏ô‡∏≥

### Render:
1. Settings ‚Üí Custom Domain
2. ‡πÄ‡∏û‡∏¥‡πà‡∏°: `api.smartliva.com`
3. ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ CNAME

---

## üêõ Troubleshooting

### Frontend ‡πÑ‡∏°‡πà‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏° Backend?

**Check:**
1. Environment Variable `NEXT_PUBLIC_API_URL` ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á
2. Backend URL ‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á (https://smartliva-backend.onrender.com)
3. CORS ‡πÉ‡∏ô backend ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï Vercel domain

**Fix CORS** (`app/backend/app/main.py`):
```python
from fastapi.middleware.cors import CORSMiddleware

app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "https://smartliva.vercel.app",
        "https://*.vercel.app",  # All Vercel preview deployments
        "http://localhost:3000"   # Local dev
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)
```

### Backend Slow?

- ‡πÉ‡∏ä‡πâ UptimeRobot ping ‡∏ó‡∏∏‡∏Å 5 ‡∏ô‡∏≤‡∏ó‡∏µ
- ‡∏´‡∏£‡∏∑‡∏≠ upgrade Render ‡πÄ‡∏õ‡πá‡∏ô $7/month

---

## ‚úÖ Checklist

### Backend (Render):
- [ ] Push code to GitHub
- [ ] Create Render account
- [ ] New Web Service
- [ ] Set Root Directory: `app/backend`
- [ ] Set Environment Variables
- [ ] Deploy
- [ ] Test: `curl https://smartliva-backend.onrender.com/health`

### Frontend (Vercel):
- [ ] Create `.env.production` with backend URL
- [ ] Push to GitHub
- [ ] Create Vercel account
- [ ] Import repository
- [ ] Set Root Directory: `app/frontend`
- [ ] Set Environment Variables
- [ ] Deploy
- [ ] Test: Open `https://smartliva.vercel.app`

---

## üéâ ‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!

**URLs:**
- Frontend: `https://smartliva.vercel.app`
- Backend: `https://smartliva-backend.onrender.com`
- API Docs: `https://smartliva-backend.onrender.com/docs`

**Performance:**
- ‚ö° Frontend: ~50-100ms (Vercel Edge)
- üöÄ Backend: ~200-500ms (Render Singapore)
- üåç Global CDN: Yes (Vercel)

---

## üìö Resources

- [Vercel Docs](https://vercel.com/docs)
- [Render Docs](https://render.com/docs)
- [Next.js Environment Variables](https://nextjs.org/docs/basic-features/environment-variables)
- [FastAPI CORS](https://fastapi.tiangolo.com/tutorial/cors/)

---

**Happy Deploying! ‚ö°üöÄ**
